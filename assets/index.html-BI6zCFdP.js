import{_ as a,c as t,a as i,o as n}from"./app-CpFOj0gG.js";const s="/learning-ai/assets/librechat_interface-CYKYbYEb.png",r="/learning-ai/assets/prompt-D9YI1LJh.png",o="/learning-ai/assets/demo_prompt-BpZVtafc.gif",l="/learning-ai/assets/assistant-BJUR0Mbm.png",p="/learning-ai/assets/multi_plugin-TCdQZhy0.png",c="/learning-ai/assets/result_prompt-C4XLLbdh.png",h={};function d(u,e){return n(),t("div",null,e[0]||(e[0]=[i('<h1 id="online-with-librechat" tabindex="-1"><a class="header-anchor" href="#online-with-librechat"><span>Online with Librechat</span></a></h1><p><img src="'+s+`" alt="librechat_interface"></p><p>LibreChat is a free, open source AI chat platform. This Web UI offers vast customization, supporting numerous AI providers, services, and integrations. Serves all AI Conversations in one place with a familiar interface, innovative enhancements, for as many users as you need.</p><p>The full librechat documentation is available <a href="https://www.librechat.ai/docs" target="_blank" rel="noopener noreferrer">here</a></p><p>Let&#39;s discover how to use LibreChat to create efficient and effective conversations with AI for developers.</p><h2 id="history" tabindex="-1"><a class="header-anchor" href="#history"><span>History</span></a></h2><p>Prompts history allows users to save and load prompts for their conversations and easily access them later. Reusing prompts can save time and effort, especially when working with multiple conversations and keep track of the context and details of a conversation.</p><h2 id="favorites" tabindex="-1"><a class="header-anchor" href="#favorites"><span>Favorites</span></a></h2><p>The favorites feature allows users to save and load favorite prompts for their conversations and easily access them later.</p><h2 id="presets" tabindex="-1"><a class="header-anchor" href="#presets"><span>Presets</span></a></h2><p>The <code>presets</code> feature allows users to save and load predefined settings for initialise a conversations. Users can import and export these presets as JSON files, set a default preset, and share them with others.</p><h2 id="preformatted-prompts" tabindex="-1"><a class="header-anchor" href="#preformatted-prompts"><span>Preformatted prompts</span></a></h2><p>The prompts feature allows users to save and load predefined prompts to use it during their conversations. You can use a prompt with the /[<code>prompt command</code>]. A prompt can have parameters, which are replaced with values when the prompt is used.</p><p><strong>Exemple of preformatted prompts : Explain the following code snippet in Java, Kotlin or Javascript</strong></p><ul><li>Click on the <code>+</code> button to add a new prompt.</li><li>name your prompt : <code>explain</code></li><li>on Text tab, you can write your prompt :</li></ul><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">Explain the following {{language:Java|Kotlin|Javascript}} snippet of code: </span>
<span class="line">{{code}}</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="`+r+'" alt="preformatted_prompts_config"></p><ul><li>Now you can use the <code>/explain</code> command to get the explanation of the code snippet.</li></ul><p><img src="'+o+'" alt="preformatted_prompts_usage"></p><h2 id="ai-providers" tabindex="-1"><a class="header-anchor" href="#ai-providers"><span>AI providers</span></a></h2><h3 id="azure-openai" tabindex="-1"><a class="header-anchor" href="#azure-openai"><span>Azure OpenAI</span></a></h3><p>Azure OpenAI Service provides REST API access to OpenAI&#39;s powerful language models, including the o1-preview, o1-mini, GPT-4o, GPT-4o mini, GPT-4 Turbo with Vision, GPT-4, GPT-3.5-Turbo, and Embeddings model series.</p><h3 id="google-gemini" tabindex="-1"><a class="header-anchor" href="#google-gemini"><span>Google Gemini</span></a></h3><p>Gemini is a large language model (LLM) developed by Google. It&#39;s designed to be a multimodal AI, meaning it can work with and understand different types of information, including text, code, audio, and images. Google positions Gemini as a highly capable model for a range of tasks, from answering questions and generating creative content to problem-solving and more complex reasoning. There are different versions of Gemini, optimized for different tasks and scales.</p><h3 id="anthropic-claude" tabindex="-1"><a class="header-anchor" href="#anthropic-claude"><span>Anthropic Claude</span></a></h3><p>Claude is an Artificial Intelligence, trained by Anthropic. Claude can process large amounts of information, brainstorm ideas, generate text and code, help you understand subjects, coach you through difficult situations, help simplify your busywork so you can focus on what matters most, and so much more.</p><h2 id="assistants" tabindex="-1"><a class="header-anchor" href="#assistants"><span>Assistants</span></a></h2><p>The Assistants API enables the creation of AI assistants, offering functionalities like code interpreter, knowledge retrieval of files, and function execution. The Assistants API allows you to build AI assistants within your own applications for specific needs. An Assistant has instructions and can leverage models, tools, and files to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, File Search, and Function calling.</p><p><img src="'+l+`" alt="assistant"></p><h2 id="plugins" tabindex="-1"><a class="header-anchor" href="#plugins"><span>Plugins</span></a></h2><p>The plugins endpoint opens the door to prompting LLMs in new ways other than traditional input/output prompting.</p><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>Every additional plugin selected will increase your token usage as there are detailed instructions the LLM needs for each one For best use, be selective with plugins per message and narrow your requests as much as possible</p></div><h3 id="dall-e-3" tabindex="-1"><a class="header-anchor" href="#dall-e-3"><span>DALL-E 3</span></a></h3><p>Dall-e 3 is a librechat Plugin for generating images from text. You can use it to generate images from text, such as product descriptions, product images, or even documentation images to illustrate your technical documentation.</p><h3 id="confluence" tabindex="-1"><a class="header-anchor" href="#confluence"><span>Confluence</span></a></h3><p>Ask confluence is a librechat Plugin for Confluence documents.</p><h3 id="it-support" tabindex="-1"><a class="header-anchor" href="#it-support"><span>IT support</span></a></h3><p>Ask for IT support enable you to get support from the IT team and create WLSD tickets from your chats.</p><h3 id="wolf" tabindex="-1"><a class="header-anchor" href="#wolf"><span>WOLF</span></a></h3><p><code>Wolf</code> is a librechat Plugin for WL Managagement System documents. The sharepoint documention is available <a href="https://worldline365.sharepoint.com/sites/AAC815" target="_blank" rel="noopener noreferrer">here</a></p><p>Ask to WorldLine management system Friend everything you are looking for in the WMS content. AskWOLF plugin is meant to help you navigate through the multitude of information provided by the WMS (Applicable Policies, Processes &amp; Procedures, Transversal &amp; Operations SP pages links, â€¦). This Worldline LibreChat plugin relies on ChatGPT technologies.</p><p>â€‹â€‹â€‹â€‹â€‹â€‹â€‹Worldline Management System (WMS) is the Group reference for all information pertaining to our operating model such as applicable policies, processes and governance structures. Key responsibilities are :</p><ul><li>consistently address its customersâ€™ and marketsâ€™ requirements across all its geographies</li><li>continuous improvement of customer satisfaction through effective application of WMS</li><li>correct interpretation of applicable ISO standards requirements</li></ul><p>Example of prompts:</p><ul><li>AskWOLF: What is the WMS?</li><li>AskWOLF: What are the policies?</li><li>AskWOLF: What are the processes?</li></ul><h3 id="browse-plugins" tabindex="-1"><a class="header-anchor" href="#browse-plugins"><span>Browse plugins</span></a></h3><p>Retrieve data from internet and use it to generate a response.</p><h2 id="plugin-mixing" tabindex="-1"><a class="header-anchor" href="#plugin-mixing"><span>Plugin mixing</span></a></h2><p>You can mix plugins to create more complex prompts. For example, you can use the DALL-E 3 plugin to generate images from text and then use the IT support plugin to get support from the IT team.</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">Generate the favicon 16x16 pixels based on the content found in </span>
<span class="line">https://worldline.github.io/learning-ai/overview/ with Browser plugin </span>
<span class="line">and generate the favicon with DallE. I want no background and black and white image</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="`+p+'" alt="prompt"><img src="'+c+'" alt="Favicon"></p><h2 id="rag" tabindex="-1"><a class="header-anchor" href="#rag"><span>RAG</span></a></h2><p>RAG is possible with LibreChat. You can use RAG to create a conversation with the AI. To can add files to the conversation, you go to the file tab and select the file you want to add. Then the file will be added to the file manager and you can use it in the prompt.</p><p>The file can be an png, a video, a text file, or a PDF file.</p><h2 id="ðŸ§ª-exercises" tabindex="-1"><a class="header-anchor" href="#ðŸ§ª-exercises"><span>ðŸ§ª Exercises</span></a></h2><h4 id="_1-prompt-creation" tabindex="-1"><a class="header-anchor" href="#_1-prompt-creation"><span>1. Prompt creation</span></a></h4><p>Select one prompt engineering technique and make a prompt in librechat that can be called with the <code>/[prompt_name]</code> command.</p><h4 id="_2-plugins-mixing" tabindex="-1"><a class="header-anchor" href="#_2-plugins-mixing"><span>2. Plugins mixing</span></a></h4><p>Use the Browse and Dall-E plugins to create a prompt that generates a a favicon based on the content of this learning-ai website.</p><h4 id="_3-make-your-own-assistant" tabindex="-1"><a class="header-anchor" href="#_3-make-your-own-assistant"><span>3. Make your own assistant</span></a></h4><p>Choose your favorite topic ( cooking, travel, sports, etc.) and create an assistant that can answer questions about it. You can share documents, files and instructions to configure your custom assistant and use it.</p><h2 id="ðŸ“–-further-readings" tabindex="-1"><a class="header-anchor" href="#ðŸ“–-further-readings"><span>ðŸ“– Further readings</span></a></h2><ul><li><a href="https://worldline365.sharepoint.com/:u:/r/sites/GenerativeAIQA/SitePages/LibreChat-guides.aspx?csf=1&amp;web=1&amp;e=evKJpU" target="_blank" rel="noopener noreferrer">LibreChat Worldline guides</a></li><li><a href="https://librechat.as8677.net/login" target="_blank" rel="noopener noreferrer">LibreChat worldline instance</a></li><li><a href="https://www.librechat.ai/" target="_blank" rel="noopener noreferrer">LibreChat official website</a></li><li><a href="https://github.com/danny-avila/LibreChat" target="_blank" rel="noopener noreferrer">LibreChat Github repository</a></li><li><a href="">Gemini Prompting guide</a></li><li><a href="https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search" target="_blank" rel="noopener noreferrer">Azure search</a></li><li><a href="https://programmablesearchengine.google.com/about/" target="_blank" rel="noopener noreferrer">Google programmable search engine</a></li><li><a href="https://www.anthropic.com/" target="_blank" rel="noopener noreferrer">Claude AI</a></li><li><a href="https://platform.openai.com/docs/assistants/overview" target="_blank" rel="noopener noreferrer">OpenAI Assistant feature</a></li></ul>',63)]))}const g=a(h,[["render",d],["__file","index.html.vue"]]),f=JSON.parse('{"path":"/llm/","title":"Online with Librechat","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"History","slug":"history","link":"#history","children":[]},{"level":2,"title":"Favorites","slug":"favorites","link":"#favorites","children":[]},{"level":2,"title":"Presets","slug":"presets","link":"#presets","children":[]},{"level":2,"title":"Preformatted prompts","slug":"preformatted-prompts","link":"#preformatted-prompts","children":[]},{"level":2,"title":"AI providers","slug":"ai-providers","link":"#ai-providers","children":[{"level":3,"title":"Azure OpenAI","slug":"azure-openai","link":"#azure-openai","children":[]},{"level":3,"title":"Google Gemini","slug":"google-gemini","link":"#google-gemini","children":[]},{"level":3,"title":"Anthropic Claude","slug":"anthropic-claude","link":"#anthropic-claude","children":[]}]},{"level":2,"title":"Assistants","slug":"assistants","link":"#assistants","children":[]},{"level":2,"title":"Plugins","slug":"plugins","link":"#plugins","children":[{"level":3,"title":"DALL-E 3","slug":"dall-e-3","link":"#dall-e-3","children":[]},{"level":3,"title":"Confluence","slug":"confluence","link":"#confluence","children":[]},{"level":3,"title":"IT support","slug":"it-support","link":"#it-support","children":[]},{"level":3,"title":"WOLF","slug":"wolf","link":"#wolf","children":[]},{"level":3,"title":"Browse plugins","slug":"browse-plugins","link":"#browse-plugins","children":[]}]},{"level":2,"title":"Plugin mixing","slug":"plugin-mixing","link":"#plugin-mixing","children":[]},{"level":2,"title":"RAG","slug":"rag","link":"#rag","children":[]},{"level":2,"title":"ðŸ§ª Exercises","slug":"ðŸ§ª-exercises","link":"#ðŸ§ª-exercises","children":[]},{"level":2,"title":"ðŸ“– Further readings","slug":"ðŸ“–-further-readings","link":"#ðŸ“–-further-readings","children":[]}],"git":{"updatedTime":1732110036000,"contributors":[{"name":"Brah","username":"Brah","email":"brah.gharbi@gmail.com","commits":3,"url":"https://github.com/Brah"}]},"filePathRelative":"llm/README.md"}');export{g as comp,f as data};
