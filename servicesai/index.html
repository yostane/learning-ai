<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.18" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <link rel="icon" href="/learning-ai/favicon.ico"><link rel="manifest" href="/learning-ai/manifest.webmanifest"><meta name="theme-color" content="#00A67E"><title>AI for services</title><meta name="description" content="">
    <link rel="preload" href="/learning-ai/assets/style-DxALa4jE.css" as="style"><link rel="stylesheet" href="/learning-ai/assets/style-DxALa4jE.css">
    <link rel="modulepreload" href="/learning-ai/assets/app-CpFOj0gG.js"><link rel="modulepreload" href="/learning-ai/assets/index.html-BQRe6DYZ.js">
    <link rel="prefetch" href="/learning-ai/assets/index.html-CE996aio.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-RxFH6ihY.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-BI6zCFdP.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-BKkRnedg.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-DWyx6_xv.js" as="script"><link rel="prefetch" href="/learning-ai/assets/index.html-ePbs5NrP.js" as="script"><link rel="prefetch" href="/learning-ai/assets/404.html-OWTotRQR.js" as="script"><link rel="prefetch" href="/learning-ai/assets/setupDevtools-7MC2TMWH-BvTCuljQ.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/learning-ai/"><img class="vp-site-logo" src="/learning-ai/logo_worldline.png" alt><!----></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/worldline/learning-ai" aria-label="⭐ Contribute!" rel="noopener noreferrer" target="_blank"><!---->⭐ Contribute!<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/worldline/learning-ai" aria-label="⭐ Contribute!" rel="noopener noreferrer" target="_blank"><!---->⭐ Contribute!<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/" aria-label="Home"><!---->Home<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/overview/" aria-label="Let&#39;s start"><!---->Let&#39;s start<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/use/" aria-label="Prompt with AI"><!---->Prompt with AI<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/llm/" aria-label="Online with Librechat"><!---->Online with Librechat<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/offline/" aria-label="Offline with LM Studio"><!---->Offline with LM Studio<!----></a><!----></li><li><a class="route-link auto-link vp-sidebar-item vp-sidebar-heading" href="/learning-ai/develop/" aria-label="Develop with AI"><!---->Develop with AI<!----></a><!----></li><li><a class="route-link route-link-active auto-link vp-sidebar-item vp-sidebar-heading active" href="/learning-ai/servicesai/" aria-label="AI for services"><!---->AI for services<!----></a><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div class="theme-default-content" vp-content><!--[--><!--]--><div><h1 id="ai-for-services" tabindex="-1"><a class="header-anchor" href="#ai-for-services"><span>AI for services</span></a></h1><h2 id="definitions" tabindex="-1"><a class="header-anchor" href="#definitions"><span>Definitions</span></a></h2><h3 id="google-colab" tabindex="-1"><a class="header-anchor" href="#google-colab"><span>Google Colab</span></a></h3><p>You can use <a href="https://colab.research.google.com/" target="_blank" rel="noopener noreferrer">Google collab</a> for a simple to use notebook environment for machine learning and data science. It will provide a container with all the necessary libraries and tools to run your code and live editing interface through a browser.</p><p>A notebook is a document that contains live code, equations, visualizations, and narrative text. You can use Colab to create, share, and collaborate on Jupyter notebooks with others.</p><div class="hint-container tip"><p class="hint-container-title">User interraction with collab</p><p>You can store your API keysafely in the userdata of your colab environment. Also you can upload files to your colab environment as follows:</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"></span>
<span class="line"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> files</span>
<span class="line"><span class="token keyword">from</span> google<span class="token punctuation">.</span>colab <span class="token keyword">import</span> userdata  <span class="token comment"># For retrieving API keys</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 1. Upload the file to your current colab environment ( a upload button will appear at the execution of the code)</span></span>
<span class="line">uploaded <span class="token operator">=</span> files<span class="token punctuation">.</span>upload<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">for</span> fn <span class="token keyword">in</span> uploaded<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span></span>
<span class="line">        name<span class="token operator">=</span>fn<span class="token punctuation">,</span> length<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>uploaded<span class="token punctuation">[</span>fn<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># get the API key from colab userdata ( left panel of colla, picto with the key)</span></span>
<span class="line">api_key<span class="token operator">=</span>userdata<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">&#39;API_KEY&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><h3 id="langchain" tabindex="-1"><a class="header-anchor" href="#langchain"><span>Langchain</span></a></h3><p>Langchain is a framework for building applications powered by language models (LLMs) like OpenAI&#39;s GPT-3. It provides a set of tools and utilities for working with LLMs, including prompt engineering, chain of thought, and memory management. Langchain is designed to be modular and extensible, allowing developers to easily integrate with different LLMs and other AI services.</p><h2 id="use-apis-mistral" tabindex="-1"><a class="header-anchor" href="#use-apis-mistral"><span>Use APIs (Mistral)</span></a></h2><div class="hint-container tip"><p class="hint-container-title">configuration</p><p><strong>To set Up Your Environment</strong></p><ul><li>Install the necessary packages using pip:<div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">pip <span class="token function">install</span> requests langchain langchain_mistralai</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul><p><strong>To obtain API Keys</strong></p><ul><li>Obtain an API key for the Mistral API <a href="https://console.mistral.ai/api-keys/" target="_blank" rel="noopener noreferrer">here</a></li></ul></div><h3 id="main-enpoints" tabindex="-1"><a class="header-anchor" href="#main-enpoints"><span>Main enpoints</span></a></h3><table><thead><tr><th>Endpoint</th><th>URL</th><th>Description</th></tr></thead><tbody><tr><td>Models</td><td><a href="https://api.mistral.ai/v1/models" target="_blank" rel="noopener noreferrer">/v1/models</a></td><td>List models that are available with your account.</td></tr><tr><td>Chat Completions</td><td><a href="https://api.mistral.ai/v1/chat/completions" target="_blank" rel="noopener noreferrer">/v1/chat/completions</a></td><td>Completion means that the LLM will generate a response based on the prompt.</td></tr><tr><td>Embeddings</td><td><a href="https://api.mistral.ai/v1/embeddings" target="_blank" rel="noopener noreferrer">/v1/embeddings</a></td><td>Embeddings means that the LLM will generate a vector representation of the input text.</td></tr></tbody></table><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> <span class="token parameter variable">-H</span> <span class="token string">&quot;Authorization: Bearer &lt;your_api_key&gt;&quot;</span> https://api.mistral.ai/v1/models</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>output :</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">[</span></span>
<span class="line">  <span class="token punctuation">{</span></span>
<span class="line">    <span class="token property">&quot;id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text-davinci-003&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;object&quot;</span><span class="token operator">:</span> <span class="token string">&quot;model&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;owned_by&quot;</span><span class="token operator">:</span> <span class="token string">&quot;user-123456789&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token property">&quot;permission&quot;</span><span class="token operator">:</span> <span class="token punctuation">[</span></span>
<span class="line">      <span class="token punctuation">{</span></span>
<span class="line">        <span class="token property">&quot;id&quot;</span><span class="token operator">:</span> <span class="token string">&quot;user-123456789&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;object&quot;</span><span class="token operator">:</span> <span class="token string">&quot;permission&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_create_engine&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_sampling&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_logprobs&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_search&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_view&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;allow_fine_tuning&quot;</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;organization&quot;</span><span class="token operator">:</span> <span class="token string">&quot;org-123456789&quot;</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;group&quot;</span><span class="token operator">:</span> <span class="token null keyword">null</span><span class="token punctuation">,</span></span>
<span class="line">        <span class="token property">&quot;is_blocking&quot;</span><span class="token operator">:</span> <span class="token boolean">false</span></span>
<span class="line">      <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">]</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line">  ...</span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="json-mode" tabindex="-1"><a class="header-anchor" href="#json-mode"><span>Json Mode</span></a></h3><p><code>Json mode</code> is a feature that allows you to send structured data to the model through the API instead of a text prompt. To use Json mode, you need to select the right endpoint in the API explorer and specify the input format as JSON in the prompt.</p><p>For OpenAI API, you can use the following format :</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text-davinci-003&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Translate the following text to French: &#39;Hello, how are you?&#39;&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">100</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">curl</span> <span class="token parameter variable">-H</span> <span class="token string">&quot;Authorization: Bearer &lt;your_api_key&gt;&quot;</span> <span class="token parameter variable">-H</span> <span class="token string">&quot;Content-Type: application/json&quot;</span> <span class="token parameter variable">-d</span> <span class="token string">&#39;{&quot;model&quot;: &quot;text-davinci-003&quot;, &quot;prompt&quot;: &quot;Translate the following text to French: &#39;</span>Hello, how are you?<span class="token string">&#39;&quot;, &quot;max_tokens&quot;: 100}&#39;</span> https://api.mistral.ai/v1/chat/completions</span>
<span class="line"></span>
<span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token string">&quot;id&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;chatcmpl-123456789&quot;</span>,</span>
<span class="line">  <span class="token string">&quot;object&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;chat.completion&quot;</span>,</span>
<span class="line">  <span class="token string">&quot;created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1679341456</span>,</span>
<span class="line">  <span class="token string">&quot;model&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;text-davinci-003&quot;</span>,</span>
<span class="line">  <span class="token string">&quot;choices&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">      <span class="token string">&quot;index&quot;</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,</span>
<span class="line">      <span class="token string">&quot;message&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;role&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;assistant&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;content&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Bonjour, comment ça va?&quot;</span></span>
<span class="line">      <span class="token punctuation">}</span>,</span>
<span class="line">      <span class="token string">&quot;finish_reason&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;stop&quot;</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line">  <span class="token punctuation">]</span>,</span>
<span class="line">  <span class="token string">&quot;usage&quot;</span><span class="token builtin class-name">:</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;prompt_tokens&quot;</span><span class="token builtin class-name">:</span> <span class="token number">5</span>,</span>
<span class="line">    <span class="token string">&quot;completion_tokens&quot;</span><span class="token builtin class-name">:</span> <span class="token number">7</span>,</span>
<span class="line">    <span class="token string">&quot;total_tokens&quot;</span><span class="token builtin class-name">:</span> <span class="token number">12</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="structured-outputs" tabindex="-1"><a class="header-anchor" href="#structured-outputs"><span>Structured Outputs</span></a></h3><p><code>Structured outputs</code> are a feature that allows you to receive structured data from the model through the API. It is useful for working with models that require structured outputs, such as JSON.</p><p>To use structured outputs, you need to select the right endpoint in the API explorer and specify the output format in the prompt.</p><p>for OpenAI API, you can use the following format :</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text-davinci-003&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Translate the following text to French: &#39;Hello, how are you?&#39;&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;output&quot;</span><span class="token operator">:</span> <span class="token string">&quot;json&quot;</span>  </span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>the structured output can be as follow :</p><div class="language-json line-numbers-mode" data-highlighter="prismjs" data-ext="json" data-title="json"><pre><code><span class="line"><span class="token punctuation">{</span></span>
<span class="line">  <span class="token property">&quot;model&quot;</span><span class="token operator">:</span> <span class="token string">&quot;text-davinci-003&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;prompt&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Translate the following text to French: &#39;Hello, how are you?&#39;&quot;</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;max_tokens&quot;</span><span class="token operator">:</span> <span class="token number">100</span><span class="token punctuation">,</span></span>
<span class="line">  <span class="token property">&quot;output&quot;</span><span class="token operator">:</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token property">&quot;text&quot;</span><span class="token operator">:</span> <span class="token string">&quot;Bonjour, comment ça va?&quot;</span></span>
<span class="line">  <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="🧪-exercises" tabindex="-1"><a class="header-anchor" href="#🧪-exercises"><span>🧪 Exercises</span></a></h3><h4 id="request-an-llm-with-with-basic-rest-request" tabindex="-1"><a class="header-anchor" href="#request-an-llm-with-with-basic-rest-request"><span>Request an LLM with with basic REST request</span></a></h4><p>Create a Python application that generates humorous motivational quotes for developers based on their name, favorite programming language, and a brief description of their current project or challenge.</p><div class="hint-container tip"><p class="hint-container-title">Library for making API calls</p><p>You can use <a href="https://requests.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">requests</a> for making API calls in Python.</p></div><p><strong>Expected Output</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">Enter your name: Ibrahim</span>
<span class="line">Enter your favorite programming language: kotlin</span>
<span class="line">Enter your current project description: conference app with KMP</span>
<span class="line"></span>
<span class="line">--- Motivational Quote ---</span>
<span class="line">Quote: <span class="token string">&quot;Code like you just ate a burrito... with passion, speed, and a little bit of mess!&quot;</span></span>
<span class="line">Author: Unknown</span>
<span class="line">--------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><a href="https://docs.mistral.ai/api/#tag/models/operation/list_models_v1_models_get" target="_blank" rel="noopener noreferrer">API Model list</a></li><li><a href="https://docs.mistral.ai/api/#tag/chat/operation/chat_completion_v1_chat_completions_post" target="_blank" rel="noopener noreferrer">Chat completions</a></li></ul><details class="hint-container details"><summary>Solution</summary><p><a href="https://colab.research.google.com/drive/1CHb_WX3kZaCKShHdCI-4zut1Ro0HqgPd?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details><h2 id="use-langchain-mistral" tabindex="-1"><a class="header-anchor" href="#use-langchain-mistral"><span>Use Langchain (Mistral)</span></a></h2><h3 id="support" tabindex="-1"><a class="header-anchor" href="#support"><span>Support</span></a></h3><p>Depending on the LLM, langchain provides different APIs. Have a look at the following table <a href="https://python.langchain.com/docs/integrations/chat/mistralai/" target="_blank" rel="noopener noreferrer">here</a> to see which APIs are available for your LLM.</p><table><thead><tr><th>Model Features</th><th>Tool Calling</th><th>Structured Output</th><th>JSON Mode</th><th>Image Input</th><th>Audio Input</th><th>Video Input</th></tr></thead><tbody><tr><td></td><td>✅</td><td>✅</td><td>✅</td><td>❌</td><td>❌</td><td>❌</td></tr></tbody></table><p>To use langchain with mistral, you need to install the <code>langchain_mistralai</code> package and create a <code>ChatMistralAI</code> object.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> langchain_mistralai<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatMistralAI</span>
<span class="line"><span class="token comment"># Define your API key and model</span></span>
<span class="line">API_KEY <span class="token operator">=</span> <span class="token string">&#39;your_api_key&#39;</span>  <span class="token comment"># Replace with your actual Mistral API key</span></span>
<span class="line">MISTRAL_API_URL <span class="token operator">=</span> <span class="token string">&#39;https://api.mistral.ai/v1/chat/completions&#39;</span></span>
<span class="line">llm <span class="token operator">=</span> ChatMistralAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">&quot;open-mistral-7b&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="prompt-templating" tabindex="-1"><a class="header-anchor" href="#prompt-templating"><span>Prompt templating</span></a></h3><p><a href="https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#prompttemplate" target="_blank" rel="noopener noreferrer"><code>Prompt templating</code></a> is a powerful feature that allows you to create dynamic prompts based on the input data. It enables you to generate prompts that are tailored to the specific requirements of your application.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate</span>
<span class="line"></span>
<span class="line">prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span></span>
<span class="line">    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;text&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;language&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    template<span class="token operator">=</span><span class="token string">&quot;translate the following text to {language}: {text}&quot;</span><span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="chain" tabindex="-1"><a class="header-anchor" href="#chain"><span>Chain</span></a></h3><p><a href="https://python.langchain.com/v0.1/docs/modules/chains/" target="_blank" rel="noopener noreferrer"><code>Chain</code></a> Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. It is a sequence of calls that are executed in order, with the output of one call being the input for the next call.It enables you to create complex workflows by combining the output of one LLM call with the input of another. This is useful for tasks that require multiple steps or interactions with external systems.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain</span>
<span class="line"></span>
<span class="line">input_data <span class="token operator">=</span> <span class="token punctuation">{</span></span>
<span class="line">    <span class="token string">&quot;text&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Hello, how are you?&quot;</span><span class="token punctuation">,</span></span>
<span class="line">    <span class="token string">&quot;language&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;French&quot;</span></span>
<span class="line"><span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line">chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm_model</span>
<span class="line">response<span class="token operator">=</span>chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_data<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Multiple prompt can be chained together to create complex workflows.</p><h4 id="aimessage" tabindex="-1"><a class="header-anchor" href="#aimessage"><span>AIMessage</span></a></h4><p><a href="https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html" target="_blank" rel="noopener noreferrer"><code>AIMessage</code></a> is returned from a chat model as a response to a prompt. It contains the message type, content, and any additional parameters.</p><h3 id="🧪-exercise" tabindex="-1"><a class="header-anchor" href="#🧪-exercise"><span>🧪 Exercise</span></a></h3><h4 id="request-an-llm-in-json-mode-with-structured-output-in-json-format" tabindex="-1"><a class="header-anchor" href="#request-an-llm-in-json-mode-with-structured-output-in-json-format"><span>Request an LLM in JSON mode with structured output in JSON format</span></a></h4><p>Create a Python application that generates humorous motivational quotes for developers based on their name, favorite programming language, and a brief description of their current project or challenge.</p><p><strong>Expected Output</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">Enter your name: Ibrahim</span>
<span class="line">Enter your favorite programming language: kotlin</span>
<span class="line">Enter your current project description: conference app with KMP</span>
<span class="line"></span>
<span class="line">--- Motivational Quote ---</span>
<span class="line">Quote: <span class="token string">&quot;Code like you just ate a burrito... with passion, speed, and a little bit of mess!&quot;</span></span>
<span class="line">Author: Unknown</span>
<span class="line">--------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Steps</strong></p><p>Create a function <code>get_developer_motivation(name, language, project_description)</code> that:</p><ul><li>Takes a developer&#39;s name, their favorite programming language, and a brief description of their current project or challenge as input.</li><li>Uses langchain to send a request to the LLM to generate a humorous motivational quote.</li><li>Returns a structured response containing the quote, the developer&#39;s name, the programming language, and the project description.</li></ul><details class="hint-container details"><summary>Solution</summary><p><a href="https://colab.research.google.com/drive/1oGPjmOlYPwTq19HGpY8PFhsX8OuwPK22?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details><h3 id="tool-function-calling" tabindex="-1"><a class="header-anchor" href="#tool-function-calling"><span>Tool/Function calling</span></a></h3><p><a href="https://python.langchain.com/docs/how_to/tool_calling/" target="_blank" rel="noopener noreferrer"><code>Function/Tool calling</code></a> is a feature that allows the llm to call existing functions from your code. It is useful for working with functions, such as APIs, and for interacting with models that require function calls. Once a tool function is created, you can register it as a tool within LangChain for being used by the LLM.</p><h3 id="🧪-exercise-1" tabindex="-1"><a class="header-anchor" href="#🧪-exercise-1"><span>🧪 Exercise</span></a></h3><h4 id="request-an-llm-with-tool-function-calling" tabindex="-1"><a class="header-anchor" href="#request-an-llm-with-tool-function-calling"><span>Request an LLM with Tool/Function calling</span></a></h4><p>Build a command-line application that fetches weather data for a specified city using LangChain and a public weather API. The application will utilize implicit tool calling to allow the LLM to decide when to call the weather-fetching tool based on user input.</p><h5 id="output" tabindex="-1"><a class="header-anchor" href="#output"><span>Output</span></a></h5><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">Ask about the weather <span class="token punctuation">(</span>e.g., <span class="token string">&#39;Lille, France&#39;</span><span class="token punctuation">)</span>: Paris</span>
<span class="line"></span>
<span class="line">------------------------------------------------------------------------------</span>
<span class="line">The current weather <span class="token keyword">in</span> Paris is: overcast clouds with a temperature of <span class="token number">6.63</span>°C.</span>
<span class="line">------------------------------------------------------------------------------</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">Configuration</p><ul><li>Sign up for an API key from a weather service provider (e.g., OpenWeatherMap). <ul><li>You can generate your key <a href="https://home.openweathermap.org/api_keys" target="_blank" rel="noopener noreferrer">here</a></li><li>You can call the API as following :</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">   <span class="token function">curl</span> https://api.openweathermap.org/data/2.5/weather?q<span class="token operator">=</span>Lille<span class="token operator">&amp;</span><span class="token assign-left variable">appid</span><span class="token operator">=</span><span class="token operator">&lt;</span>your_api_key<span class="token operator">&gt;&amp;</span><span class="token assign-left variable">units</span><span class="token operator">=</span>metric</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li></ul></div><h5 id="steps" tabindex="-1"><a class="header-anchor" href="#steps"><span>Steps</span></a></h5><p><strong>Create the Weather Fetching Function</strong></p><ul><li>Define a function <code>fetch_weather(city: str) -&gt; dict</code> that takes a city name as input and returns the weather data as a dictionary. Use the weather API to fetch the data.</li></ul><p><strong>Register the Weather Tool</strong></p><ul><li>Use the <a href="https://python.langchain.com/docs/concepts/tools/" target="_blank" rel="noopener noreferrer"><code>Tool</code></a> class from LangChain to register the <code>fetch_weather</code> function as a tool.</li></ul><p><strong>Set Up the LangChain Components</strong></p><ul><li>Create a prompt template that asks about the weather in a specified city.</li><li>Instantiate the <code>ChatMistralAI</code> model with your Mistral API key.</li><li>Create a chain that combines the prompt template, the chat model, and the registered weather tool.</li></ul><p><strong>Handle User Input</strong></p><ul><li>Implement a function <code>handle_user_input(city)</code> that: <ul><li>Takes user input for the city name.</li><li>Invokes the chain with the input data.</li><li>Checks if the response includes <a href="https://python.langchain.com/docs/how_to/tool_calling/" target="_blank" rel="noopener noreferrer"><code>tool calls</code></a>.</li><li>Extracts the function name and arguments from the tool call and invokes the weather tool if necessary.</li><li>Returns the weather information or the LLM&#39;s response.</li></ul></li></ul><p><strong>Run the Application</strong></p><ul><li>Prompt the user to enter a city name.</li><li>Call the <code>handle_user_input</code> function with the provided city name and display the result.</li></ul><details class="hint-container details"><summary>Solution</summary><p><a href="https://colab.research.google.com/drive/16B84XU5dl2UR5XZkRtnh3MWUK0K5ZBd_?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details><h2 id="rag-for-services-llama-index" tabindex="-1"><a class="header-anchor" href="#rag-for-services-llama-index"><span>RAG for services (llama-index)</span></a></h2><p><a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/" target="_blank" rel="noopener noreferrer"><strong>llama-index</strong></a> is a powerful tool for building and deploying RAG (Retrieval Augmented Generation) applications. It provides a simple and efficient way to integrate LLMs into your applications, allowing you to retrieve relevant information from a large knowledge base and use it to generate responses. RAG is a technique that leverages the power of LLMs to augment human-generated content.</p><h3 id="rag-over-unstructured-documents" tabindex="-1"><a class="header-anchor" href="#rag-over-unstructured-documents"><span>RAG over Unstructured Documents</span></a></h3><p>Unstructured documents are a common source of information for RAG applications. These documents can be in various formats, such as text, PDF, HTML, or images. LlamaIndex provides tools for indexing and querying unstructured documents, enabling you to build powerful RAG applications that can retrieve information from a large corpus of documents.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line">documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span>fn<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">index <span class="token operator">=</span> SummaryIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> settings<span class="token operator">=</span>settings<span class="token punctuation">)</span></span>
<span class="line">query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span>response_mode<span class="token operator">=</span><span class="token string">&quot;tree_summarize&quot;</span><span class="token punctuation">,</span> llm<span class="token operator">=</span>llm<span class="token punctuation">)</span></span>
<span class="line">response <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">&quot;&lt;your_query_here&gt;&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="question-answering-qa-over-structured-data" tabindex="-1"><a class="header-anchor" href="#question-answering-qa-over-structured-data"><span>Question Answering (QA) over Structured Data</span></a></h3><p>Structured Data is another common source of information for RAG applications. This data is typically stored in databases or spreadsheets and can be queried using SQL or other query languages. LlamaIndex provides tools for connecting LLMs to databases and querying structured data, allowing you to build RAG applications that can retrieve information from databases.</p><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment">#The database library used in this example is SQLAlchemy</span></span>
<span class="line">sql_database <span class="token operator">=</span> SQLDatabase<span class="token punctuation">(</span>engine<span class="token punctuation">,</span> include_tables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;books&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span></span>
<span class="line">query_engine <span class="token operator">=</span> NLSQLTableQueryEngine<span class="token punctuation">(</span></span>
<span class="line">    sql_database<span class="token operator">=</span>sql_database<span class="token punctuation">,</span></span>
<span class="line">    tables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;books&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span></span>
<span class="line">    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span></span>
<span class="line">    embed_model<span class="token operator">=</span>embed_model<span class="token punctuation">,</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">&quot;Who wrote &#39;To Kill a Mockingbird&#39;?&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="🧪-exercises-1" tabindex="-1"><a class="header-anchor" href="#🧪-exercises-1"><span>🧪 Exercises</span></a></h3><h4 id="querying-on-unstructured-documents" tabindex="-1"><a class="header-anchor" href="#querying-on-unstructured-documents"><span>Querying on Unstructured Documents</span></a></h4><p>Create a Python application that provide a txt document containings a list of application comments and make sentiment analysis on it with <code>llama-index</code>.</p><p>Your customer review txt file :</p><div class="language-text line-numbers-mode" data-highlighter="prismjs" data-ext="text" data-title="text"><pre><code><span class="line">Review 1: I was very disappointed with the product. It did not meet my expectations.</span>
<span class="line">Review 2: The service was excellent! I highly recommend this company.</span>
<span class="line">Review 3: I had a terrible experience. The product was faulty, and the customer support was unhelpful.</span>
<span class="line">Review 4: I am extremely satisfied with my purchase. The quality is outstanding.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>Expected Shell Output:</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">Saving customer_reviews.txt to customer_reviews <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>.txt</span>
<span class="line">User uploaded <span class="token function">file</span> <span class="token string">&quot;customer_reviews (4).txt&quot;</span> with length <span class="token number">338</span> bytes</span>
<span class="line">The customers&#39; experiences with the company and its products vary. Some have had positive experiences, such as excellent <span class="token function">service</span> and high-quality products, <span class="token keyword">while</span> others have encountered issues with faulty products and unhelpful customer support.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>Solution</summary><p><a href="https://colab.research.google.com/drive/1HRVqcYEl2RLQDQ8l4NoGcdxiqU-6CgJa?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></details><h4 id="querying-sql-databases-with-natural-language" tabindex="-1"><a class="header-anchor" href="#querying-sql-databases-with-natural-language"><span>Querying SQL Databases with Natural Language</span></a></h4><p>Create a Python application that initializes a list of languages and their creators with <code>sqlalchemy</code> and requests the LLM to retrieve the creators of a language. The LLM should be able to understand the context and retrieve the relevant information from the database.</p><p><strong>Expected Shell Output:</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token punctuation">[</span></span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Python&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Guido van Rossum&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1991</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;JavaScript&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Brendan Eich&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1995</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Java&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;James Gosling&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1995</span></span>
<span class="line">    <span class="token punctuation">}</span>,</span>
<span class="line">    <span class="token punctuation">{</span></span>
<span class="line">        <span class="token string">&quot;language_name&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;C++&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;creator&quot;</span><span class="token builtin class-name">:</span> <span class="token string">&quot;Bjarne Stroustrup&quot;</span>,</span>
<span class="line">        <span class="token string">&quot;year_created&quot;</span><span class="token builtin class-name">:</span> <span class="token number">1985</span></span>
<span class="line">    <span class="token punctuation">}</span></span>
<span class="line"><span class="token punctuation">]</span></span>
<span class="line">Guido van Rossum created Python <span class="token keyword">in</span> <span class="token number">1991</span>.</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">Solution</p><p><a href="https://colab.research.google.com/drive/1osoFUAxRbZayftaTlCtJIqlWlj_0c3sQ?usp=sharing" target="_blank" rel="noopener noreferrer">Google Collab notebook</a></p></div><h2 id="cloudai-with-gcp" tabindex="-1"><a class="header-anchor" href="#cloudai-with-gcp"><span>CloudAI with GCP</span></a></h2><p>GCP is a suite of cloud computing services provided by Google. It includes a wide range of tools and services for building and consuming LLMs, such as Vertex AI, Google Colab, and ML Flow.</p><h3 id="large-consumer-facing" tabindex="-1"><a class="header-anchor" href="#large-consumer-facing"><span>Large Consumer-Facing</span></a></h3><ul><li><strong><a href="https://gemini.google.com/" target="_blank" rel="noopener noreferrer">Gemini:</a></strong> Google&#39;s large language model (LLM), positioned as a competitor to OpenAI&#39;s GPT models. Gemini&#39;s capabilities are integrated into various Google products and services, and are also accessible through APIs. Different versions of Gemini (e.g., Gemini Pro, Gemini Ultra) offer varying levels of capability and access. It powers several consumer-facing features across Google&#39;s ecosystem.</li><li><strong><a href="https://aistudio.google.com/" target="_blank" rel="noopener noreferrer">AI Studio:</a></strong> Cloud-based machine learning platform offered by several companies, most notably Google with its Google AI Studio (now Vertex AI Studio). It provides APIs for leading foundation models, and tools to rapidly prototype, easily tune models with your own data, and seamlessly deploy to applications.</li></ul><h3 id="vertex-ai" tabindex="-1"><a class="header-anchor" href="#vertex-ai"><span>Vertex AI</span></a></h3><p>This is the central hub for most Google Cloud&#39;s AI/ML services. It integrates and supersedes many previous offerings.</p><ul><li><strong>Custom Training:</strong> Training machine learning models using various algorithms and frameworks (TensorFlow, PyTorch, scikit-learn, XGBoost, etc.). Provides access to managed compute instances (including TPUs).</li><li><strong>Prediction:</strong> Deploying trained models for inference (making predictions). Offers different deployment options based on scale and latency requirements.</li><li><strong>Pipelines:</strong> Creating and managing machine learning workflows, including data preprocessing, model training, evaluation, and deployment, as a series of connected steps.</li><li><strong>Model Monitoring:</strong> Monitoring deployed models for performance degradation and potential issues (drift).</li><li><strong>Feature Store:</strong> Centralized repository for storing, managing, and versioning features used in machine learning models, improving collaboration and reuse.</li><li>...</li></ul><h3 id="google-cloud-apis" tabindex="-1"><a class="header-anchor" href="#google-cloud-apis"><span>Google Cloud APIs</span></a></h3><p>Pre-trained Models and APIs: Google offers numerous pre-trained models and APIs for various tasks, making it easier to integrate AI into applications without building models from scratch. Examples include:</p><ul><li><strong>Natural Language:</strong> Processing and understanding text (sentiment analysis, entity recognition, etc.).</li><li><strong>Vision:</strong> Analyzing images (object detection, image classification, optical character recognition, etc.).</li><li><strong>Speech-to-Text:</strong> Converting audio to text.</li><li><strong>Text-to-Speech:</strong> Converting text to audio.</li><li><strong>Translation API:</strong> Translating text between languages.</li><li>...</li></ul><h3 id="specialized-ai-products" tabindex="-1"><a class="header-anchor" href="#specialized-ai-products"><span>Specialized AI Products</span></a></h3><p>Beyond the core platform and APIs, Google offers several specialized AI products:</p><ul><li><strong>TensorFlow:</strong> A popular open-source machine learning framework developed by Google. While not strictly a &quot;Google Cloud&quot; product, it&#39;s deeply integrated with their services.</li><li><strong>Dialogflow:</strong> A conversational AI platform for building complex conversational experiences.</li><li>...</li></ul><h3 id="🧪-exercises-2" tabindex="-1"><a class="header-anchor" href="#🧪-exercises-2"><span>🧪 Exercises</span></a></h3><div class="hint-container warning"><p class="hint-container-title">TODO</p><h4 id="fork-and-deploy-a-model" tabindex="-1"><a class="header-anchor" href="#fork-and-deploy-a-model"><span>Fork and deploy a model</span></a></h4><h4 id="train-a-simple-model" tabindex="-1"><a class="header-anchor" href="#train-a-simple-model"><span>Train a simple model</span></a></h4><h4 id="create-a-simple-chatbot-application-with-your-instance" tabindex="-1"><a class="header-anchor" href="#create-a-simple-chatbot-application-with-your-instance"><span>Create a simple chatbot application with your instance</span></a></h4></div><h2 id="collaborative-hugging-face" tabindex="-1"><a class="header-anchor" href="#collaborative-hugging-face"><span>Collaborative (Hugging Face)</span></a></h2><p>The platform where the machine learning community collaborates on models, datasets, and applications.</p><p>Hugging Face is a platform for researchers and developers to share, explore, and build AI models. It provides a centralized repository for models, datasets, and applications, making it easy to find, use, and contribute to the growing ecosystem of AI technologies.</p><ul><li>Creating/deploy/customize a model</li><li>Pre-trained model, use behind the APIs, also a ML part, training model generation for use</li></ul><h3 id="🧪-exercise-2" tabindex="-1"><a class="header-anchor" href="#🧪-exercise-2"><span>🧪 Exercise</span></a></h3><div class="hint-container warning"><p class="hint-container-title">TODO</p><h4 id="use-a-pre-trained-model-of-worldline-fraud-detection-model" tabindex="-1"><a class="header-anchor" href="#use-a-pre-trained-model-of-worldline-fraud-detection-model"><span>Use a pre-trained model of worldline fraud detection model</span></a></h4></div><h2 id="manage-models-ml-flow" tabindex="-1"><a class="header-anchor" href="#manage-models-ml-flow"><span>Manage models (ML Flow)</span></a></h2><p>MLflow provides tools for managing experiments, tracking model versions, deploying models to various environments, and managing models in a central registry. It&#39;s designed to be platform-agnostic, meaning it can work with many different cloud providers and even on-premises infrastructure.</p><h2 id="🧪-exercise-3" tabindex="-1"><a class="header-anchor" href="#🧪-exercise-3"><span>🧪 Exercise</span></a></h2><div class="hint-container warning"><p class="hint-container-title">TODO</p><h4 id="create-a-model-registry-in-gcp-instance" tabindex="-1"><a class="header-anchor" href="#create-a-model-registry-in-gcp-instance"><span>create a model registry in GCP instance</span></a></h4></div><ol><li>Create a model registry in GCP instance</li><li>Create a model in the registry</li><li>Deploy the model to GCP instance</li></ol><h2 id="📖-further-readings" tabindex="-1"><a class="header-anchor" href="#📖-further-readings"><span>📖 Further readings</span></a></h2></div><!--[--><!--]--></div><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link label" href="https://github.com/worldline/learning-ai/edit/main/servicesai/README.md" aria-label="Edit this page" rel="noopener noreferrer" target="_blank"><!--[--><svg class="edit-icon" viewbox="0 0 1024 1024"><g fill="currentColor"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></g></svg><!--]-->Edit this page<!----></a></div><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: brah.gharbi@gmail.com">Brah</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: brah.gharbi@gmail.com">Ibrahim Gharbi</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link auto-link prev" href="/learning-ai/develop/" aria-label="Develop with AI"><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>Develop with AI</span></div></a><!----></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/learning-ai/assets/app-CpFOj0gG.js" defer></script>
  </body>
</html>
